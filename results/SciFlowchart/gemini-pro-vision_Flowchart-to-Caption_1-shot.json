{
    "2204.00424v1-Figure6-1.png": {
        "prediction": " The flowchart shows the process of indirect call relations and direct call patterns. In the first step, the program traces are collected for two use cases. In the second step, the direct call relations are extracted from the traces. In the third step, the indirect call relations are extracted from the traces. In the fourth step, the indirect call patterns are generated from the indirect call relations. In the fifth step, the direct call patterns are generated from the direct call relations.",
        "reference": "Figure 6. MSOPunet network. (S1t\u22121, S2t\u22121), (S1t, S2t) and (S1t+1, S2t+1) denotes the input pairs of optical and SAR images. S2t\u2032 denotes the reference image used to compute the loss (during training) and the metrics (at inference time from test data) from the reconstructed optical image S\u03022t."
    },
    "2202.03651v2-Figure1-1.png": {
        "prediction": " The flowchart shows the process of how to use a learned scene graph to edit a perception model. The input is a trace of the execution of the perception model on a video sequence. The output is a list of changes to the perception model that will make it more accurate.\n\nThe first step is to use the trace to identify the direct and indirect call relations between the components of the perception model. The direct call relations are the ones that are explicitly called by the perception model. The indirect call relations are the ones that are called by other components that are called by the perception model.\n\nThe next step is to use the direct and indirect call relations to identify the components of the perception model that are responsible for the errors in the trace. The components that are responsible for the errors are the ones that are called by the components that are directly or indirectly responsible for the errors.\n\nThe final step is to use the identified components to edit the perception model. The edits can be made to the weights of the components, the architecture of the components, or the data that is used to train the components.",
        "reference": "Figure 1: Instead of retrospectively discovering individual failure cases for perception, we actively search for causal interventions (edits) to existing scenes that consistently result in perception failures. The middle shows an example of a single intervention causing perception failure, which we attribute to the intervention, as opposed to the left where a combinatorial set of factors could explain the error. Consistent failures through this type of intervention constitute a challenging group for the perception model as seen on the right."
    },
    "2011.15102v2-Figure1-1.png": {
        "prediction": " The flowchart illustrates the process of using a machine learning model to solve a problem. The model is first trained on a dataset of labeled data. Then, the model is used to make predictions on new data. The predictions are then evaluated to determine how well the model is performing. If the model is not performing well, then the training data may need to be improved, or the model itself may need to be modified.\n\nThe flowchart also illustrates how a human can be involved in the process. The human can provide feedback on the model's predictions, which can be used to improve the model. The human can also provide new data to be used for training the model.\n\nThe flowchart is as follows:\n\n1. Start\n2. Train model on labeled data\n3. Use model to make predictions on new data\n4. Evaluate predictions\n5. If predictions are not good, then\n6. Improve training data or model\n7. Go to step 3\n8. End",
        "reference": "Figure 1: Learning by passing tests. A tester model creates tests with increasing levels of difficulty from a test bank to evaluate a learner model. The learner continuously improves its learning ability to deliver better solutions for passing those difficult tests."
    },
    "14078997-Figure2-1.png": {
        "prediction": " The flowchart shows the indirect call relations between functions `C1` and `C2`. The direct call relations are also shown. The indirect call patterns are shown on the right.\n\nThe leftmost part of the diagram shows how two traces `Trace 1` and `Trace 2` relate to each other. Both traces contain the same sequence of function calls `C1`, `C2`, `C3`, `C4`, `C5`, and `C6`, but in different orders. The arrows between the traces show the temporal relations between the function calls in the traces. For example, the arrow from `C1` in `Trace 1` to `C2` in `Trace 2` indicates that the call to `C2` in `Trace 2` occurs after the call to `C1` in `Trace 1`.\n\nThe middle part of the diagram shows the direct call relations between functions `C1` and `C2`. The direct call relation between two functions indicates that one function calls the other function directly. In this case, there is a direct call relation from `C1` to `C2`, indicated by the arrow from `C1` to `C2`.\n\nThe rightmost part of the diagram shows the indirect call patterns between functions `C1` and `C2`. The indirect call pattern between two functions indicates that one function calls the other function indirectly through a chain of other functions. In this case, there are two indirect call patterns between `C1` and `C2`. The first pattern is `C1` calls `C3` which calls `C2`. The second pattern is `C1` calls `C4` which calls `C2`. These patterns are indicated by the paths from `C1` to `C2` through `C3` and `C4`, respectively.",
        "reference": "Figure 2: Outline of the transformation-based model. The model is a CNN that takes as input a sequence of consecutive affine transforms between pairs of adjacent video frames. It predicts the affine transform between the last input frame and the next one in the sequence. We compute affine transforms (6 parameters per patch) for overlapping patches of size 8 \u00d7 8 in each video frame. Learning operates in the space of transformations as shown inside the dashed box. The front-end on the left is a module that estimates the affine transforms between pairs of consecutive input frames. The post-processor on the right reconstructs a frame from the predicted set of affine transforms and it is only used at test time."
    },
    "14078997-Figure3-1.png": {
        "prediction": " The figure shows execution traces and temporal relations. On the left-hand side, there are two traces, trace t1 and trace t2, each with a sequence of API calls. On the right-hand side, there are four boxes, each representing a type of temporal relation between API calls. The first box shows direct call relations, where one API call directly calls another. The second box shows indirect call relations, where one API call indirectly calls another through a chain of other API calls. The third box shows indirect call patterns, which are patterns of indirect call relations. The fourth box shows direct call patterns, which are patterns of direct call relations.",
        "reference": "Figure 3: Outline of the system predicting 4 frames ahead in time. Only affine transforms A1, A2 and A3 are provided, and the model predicts A\u03034, A\u03035, A\u03036 and A\u03037, which are used to reconstruct the next 4 frames. Since affine parameters are continuous values and the whole chain of CNNs is differentiable, the whole unrolled system can be trained by back-propagation of the error. Note that CNNs all share the same parameters"
    }
}